---
title: "Project"
author: "Travis Benedict"
date: "October 30, 2018"
output: pdf_document
---

```{r echo=TRUE}
set.seed(1)

View(results)

# Predictors are separated from vote results join on FIPS
results = read.csv('CountyLevelResults.csv')
facts = read.csv('county_facts.csv')
descriptions = read.csv('county_facts_dictionary.csv')

###Point Diff Column Calculation
results$points_diff_rep = ((results$votes_dem - results$votes_gop)/results$total_votes)*-1


results$Lean <- cut(results$points_diff_rep, 
                       breaks = c(-1, -.34, -.12, -.07, -.04, .04, .07, .12, .34, 1), 
                       labels = c("Solid Democratic", "Likely Democratic", "Lean Democratic", "Tilt Democratic", "Toss-Up", "Tilt GOP", "Lean GOP", "Likely GOP", "Solid GOP"), 
                       right = FALSE)

# Remove rows without results and identifier columns
joined_facts_results = merge(facts, results[c("combined_fips", "Lean", "points_diff_rep")], by.x="Fips", by.y="combined_fips")
cleaned_facts = data.frame(joined_facts_results[c(-1, -2, -3, -length(joined_facts_results[1,]))])

scaled_facts = scale(cleaned_facts)



plot(hclust(dist(scaled_facts[sample(length(scaled_facts[,1]), 100),]), method="complete"), main="Complete Linkage", labels=F)
plot(hclust(dist(scaled_facts[sample(length(scaled_facts[,1]), 100),]), method="single"), main="Single Linkage",  labels=F)
plot(hclust(dist(scaled_facts[sample(length(scaled_facts[,1]), 100),]), method="average"), main="Average Linkage",  labels=F)



#########PCA
prin_comp <- prcomp(scaled_facts, scale. = F)

summary(prin_comp)

#compute standard deviation of each principal component
std_dev <- prin_comp$sdev

#compute variance
pr_var <- std_dev^2

#check variance of first 10 components
pr_var[1:length(scaled_facts)]

#proportion of variance explained
prop_varex <- pr_var/sum(pr_var)
prop_varex[1:length(scaled_facts)]

#scree plot
plot(prop_varex, xlab = "Principal Component",
             ylab = "Proportion of Variance Explained",
             type = "b")

#cumulative scree plot
plot(cumsum(prop_varex), xlab = "Principal Component",
              ylab = "Cumulative Proportion of Variance Explained",
              type = "b")
abline(h=0.9)
abline(v=17)


# COMBINE THE FACTS WITH the LABEL COLUMN USING FIPS


autoplot(prin_comp, data = scaled_facts, colour = 'Lean', loadings = TRUE, loadings.colour = 'blue',
         loadings.label = TRUE, loadings.label.size = 3) +
  ggtitle("First two PC's using Original Variables")


# Data from first 17 principal components
pc_data <- prin_comp$x[,1:17]

plot(hclust(dist(pc_data[sample(length(pc_data[,1]), 250),]), method="complete"), main="Complete Linkage", labels=F)

library(magrittr)
library(dplyr)
library(mclust)

c_pc = mclustBIC(pc_data, G=1:20)
plot(c_pc)

# Best cluster model is k=10 VVV
summary(c_pc)

em_clusters_pc = Mclust(pc_data, G=10, modelNames = "VVV")

# Possibly compare the EM results to kmeans with k=10

cluster_id_pc = em_clusters_pc$classification

cluster_count_pc = data.frame(cluster_id_pc) %>%
  group_by(cluster_id_pc) %>%
  summarise(n = n())

state_cluster_counts_pc = cbind(joined_facts_results[1:3], cluster_id_pc) %>% 
  group_by(state_abbreviation, cluster_id_pc) %>%
  summarise(count = n())

Lean_cluster_counts_pc = data.frame(cbind(joined_facts_results[length(joined_facts_results)], cluster_id_pc)) %>% 
  group_by(Lean, cluster_id_pc) %>%
  summarise(count = n())

View(Lean_cluster_counts_pc)

plot(jitter(cluster_id_pc), jitter(as.numeric(joined_facts_results$Lean)))

Lean_counts = joined_facts_results[length(joined_facts_results)] %>%
  group_by(Lean) %>%
  summarise(count = n())

merged_lean_counts_pc = merge(Lean_cluster_counts_pc, Lean_counts, by.x="Lean", by.y="Lean")
merged_lean_counts_pc$pct = merged_lean_counts_pc$count.x / merged_lean_counts_pc$count.y

plot(merged_lean_counts_pc$cluster_id, as.numeric(merged_lean_counts_pc$Lean), cex = 10 * merged_lean_counts_pc$pct, xlab = "Cluster ID", ylab = "Solid Dem to Solid GOP", main = "Percentage of Lean By Cluster Based on First 17 Pcs")


# Try clustering with scaled data instead of pc
c = mclustBIC(scaled_facts, G=5:15)
plot(c)

# Best cluster model is k=7 VEV
summary(c)

em_clusters = Mclust(scaled_facts, G=7, modelNames = "VEV")

# Possibly compare the EM results to kmeans with k=10

cluster_id = em_clusters$classification

cluster_count = data.frame(cluster_id) %>%
  group_by(cluster_id) %>%
  summarise(n = n())

state_cluster_counts = cbind(joined_facts_results[1:3], cluster_id) %>% 
  group_by(state_abbreviation, cluster_id) %>%
  summarise(count = n())

Lean_cluster_counts = data.frame(cbind(joined_facts_results[length(joined_facts_results)], cluster_id)) %>% 
  group_by(Lean, cluster_id) %>%
  summarise(count = n())

View(Lean_cluster_counts)

# Note that there are many more Solid GOP than Solid Dem counties
plot(jitter(cluster_id), jitter(as.numeric(joined_facts_results$Lean)))

merged_lean_counts = merge(Lean_cluster_counts, Lean_counts, by.x="Lean", by.y="Lean")
merged_lean_counts$pct = merged_lean_counts$count.x / merged_lean_counts$count.y

plot(merged_lean_counts$cluster_id, as.numeric(merged_lean_counts$Lean), cex = 10 * merged_lean_counts$pct, xlab = "Cluster ID", ylab = "Solid Dem to Solid GOP", main = "Percentage of Lean By Cluster")



# Try clustering just based on pct non hispanic White, pct college degree, per capita income
expected_trump = scaled_facts[, c("RHI825214", "EDU685213", "INC910213")]

trump_bic = mclustBIC(expected_trump, G=1:20)
plot(trump_bic)

# Best cluster model is k=8 VVV
summary(trump_bic)

em_trump_clusts = Mclust(expected_trump, G=8, modelNames = "VVV")

cluster_id_trump = em_trump_clusts$classification

cluster_count_trump = data.frame(cluster_id_trump) %>%
  group_by(cluster_id_trump) %>%
  summarise(n = n())

state_cluster_counts_trump = cbind(joined_facts_results[1:3], cluster_id_trump) %>% 
  group_by(state_abbreviation, cluster_id_trump) %>%
  summarise(count = n())

Lean_cluster_counts_trump = data.frame(cbind(joined_facts_results[length(joined_facts_results)], cluster_id_trump)) %>% 
  group_by(Lean, cluster_id_trump) %>%
  summarise(count = n())

merged_lean_counts_trump = merge(Lean_cluster_counts_trump, Lean_counts, by.x="Lean", by.y="Lean")
merged_lean_counts_trump$pct = merged_lean_counts_trump$count.x / merged_lean_counts_trump$count.y

plot(merged_lean_counts_trump$cluster_id, as.numeric(merged_lean_counts_trump$Lean), cex = 10 * merged_lean_counts_trump$pct, xlab = "Cluster ID", ylab = "Solid Dem to Solid GOP", main = "% of Lean By Cluster Based on % White, % College Degree, Income")

clPairs(expected_trump, joined_facts_results[,length(joined_facts_results)], lower.panel=NULL)
clPairsLegend(0, 0.46, class = clp$class,
col = clp$col, pch = clp$pch)
```

# Model Fitting
```{r, echo=TRUE}
library(VGAM)
set.seed(1)

# Fit a logit model with just non hispanic white and college dregree
joined_facts_results$GOPDem[joined_facts_results$points_diff_rep < 0] <- 0
joined_facts_results$GOPDem[joined_facts_results$points_diff_rep > 0] <- 1

kFold <- function(x, k) split(sample(1:nrow(x)), cut(seq_along(sample(1:nrow(x))), k, labels = FALSE)) 

kFoldCVLogit <- function(y, x, k, columns, link){
  folds = kFold(x, k)

  mses = c()
  for (i in 1:k) {
    testIndexes = folds[[i]]
    testData = x[testIndexes, ]
    trainData = x[-testIndexes, ]
    
    fit <- glm(y[-testIndexes] ~ ., data=data.frame(trainData[,columns]), 
                family=(binomial(link = link)))
    predicted <- predict(fit, data.frame(testData[,columns]), type="response")
    mse = sum((y[testIndexes] - predicted)^2)
    mses = c(mses, mse)
  }

list(mse, fit)
}
y = joined_facts_results$GOPDem
x = scaled_facts
k = 10
columns = c("RHI825214", "EDU685213")
link = "logit"
result = kFoldCVLogit(y, x, k, columns, link)
mse = result[[1]]
model = result[[2]]



# MAKE NOTE OF SCORING USED FOR CROSS VALIDATION

kFoldCVMultinomial <- function(y, x, k, columns, link){
  folds = kFold(x, k)

  mses = c()
  for (i in 1:k) {
    testIndexes = folds[[i]]
    testData = x[testIndexes, ]
    trainData = x[-testIndexes, ]
    
    fit <- vglm(y[-testIndexes] ~ ., data=data.frame(trainData[,columns]), 
                family=(multinomial))
    predicted <- predict(fit, data.frame(testData[,columns]), type="response")
    # Calculating the MSE using Brier Score
    mse = sum((y[testIndexes] - predicted[cbind(seq_along(y[testIndexes]), y[testIndexes])])^2) 
    
    mses = c(mses, mse)
  }
  
list(sum(mses) / nrow(x), fit)
}
y = as.numeric(joined_facts_results$Lean)
x = scaled_facts
k = 10
columns = c("SBO315207", "EDU685213")
link = "logit"
result = kFoldCVMultinomial(y, x, k, columns, link)
mse = result[[1]]
model = result[[2]]
summary(model)

y = as.numeric(joined_facts_results$Lean)
x = scaled_facts
k = 10
columns = c("RHI825214", "EDU685213")
link = "logit"

samp <- sample(1:3100, 250)
logit <- vglm(joined_facts_results$Lean[samp] ~ ., data=data.frame(scaled_facts[samp,c("RHI825214", "EDU685213")]), 
              family=(multinomial))


# Perform forward and backward AIC/BIC variable selection
library(glmnet)

y = joined_facts_results$GOPDem
x = scaled_facts
link = "logit"
fit_full <- glm(y[-testIndexes] ~ ., data=data.frame(x[-testIndexes,]), 
                family=(binomial(link = link)))
fit_null <- glm(y[-testIndexes] ~ 1, data=data.frame(x[-testIndexes,]), family = binomial(link = "logit"))

# Forward AIC:
forAIC = step(fit_null,  # Start with NULL model
               scope = list(lower=fit_null, upper=fit_full), # Range of models
               direction="forward",
              trace = FALSE) # Forward or backward

# Backward AIC:
backAIC = step(fit_full,  # Start with NULL model
               scope = list(lower=fit_null, upper=fit_full), # Range of models
               direction="backward",
              trace = FALSE) # Forward or backward
summary(backAIC)

# Forward BIC:
forBIC = step(fit_null,  # Start with NULL model
               scope = list(lower=fit_null, upper=fit_full), # Range of models
               direction="forward",
              k = log(length(y)),
              trace = FALSE) # Forward or backward

# Forward BIC:
backBIC = step(fit_full,  # Start with NULL model
               scope = list(lower=fit_null, upper=fit_full), # Range of models
               direction="backward",
              k = log(length(y)),
              trace = FALSE) # Forward or backward
summary(backBIC)

# Forward Backward AIC/BIC for probit
link = "probit"
fit_full <- glm(y[-testIndexes] ~ ., data=data.frame(x[-testIndexes,]), 
                family=(binomial(link = link)))
fit_null <- glm(y[-testIndexes] ~ 1, data=data.frame(x[-testIndexes,]), family = binomial(link = "logit"))

# Forward AIC:
forAIC = step(fit_null,  # Start with NULL model
               scope = list(lower=fit_null, upper=fit_full), # Range of models
               direction="forward",
              trace = FALSE) # Forward or backward

# Backward AIC:
backAIC = step(fit_full,  # Start with NULL model
               scope = list(lower=fit_null, upper=fit_full), # Range of models
               direction="backward",
              trace = FALSE) # Forward or backward
summary(backAIC)

# Forward BIC:
forBIC = step(fit_null,  # Start with NULL model
               scope = list(lower=fit_null, upper=fit_full), # Range of models
               direction="forward",
              k = log(length(y)),
              trace = FALSE) # Forward or backward

# Forward BIC:
backBIC = step(fit_full,  # Start with NULL model
               scope = list(lower=fit_null, upper=fit_full), # Range of models
               direction="backward",
              k = log(length(y)),
              trace = FALSE) # Forward or backward
summary(backBIC)


# Take each of these models and perform 10 Fold CV compare to our Baseline model of White and Education

```
